{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86832346-9e59-4811-83ff-04e2e007e515",
   "metadata": {},
   "source": [
    "# OpenAI Responses API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ea36b9-4484-4e95-a023-41e475f1af58",
   "metadata": {},
   "source": [
    "## What is the OpenAI Responses API?\n",
    "\n",
    "The Responses API is a new API released in March 2025. It is a combination of the traditional \n",
    "Chat Completions API and the Assistants API, providing support for:\n",
    "\n",
    "- **Traditional Chat Completions:** Facilitates seamless conversational AI experiences.\n",
    "- **Web Search:** Enables real-time information retrieval from the internet.\n",
    "- **File Search:** Allows searching within files for relevant data.\n",
    "\n",
    "Accordingly, the Assistants API will be retired in 2026. \n",
    "\n",
    "> **For new users, OpenAI recommends using the Responses API instead of the Chat Completions API to leverage its expanded capabilities.**\n",
    "\n",
    "For a comprehensive comparison between the Responses API and the Chat Completions API, refer to the official OpenAI documentation: \n",
    "[Responses vs. Chat Completions](https://platform.openai.com/docs/guides/responses-vs-chat-completions)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3ae0b6-d8f5-4547-be96-bafdf768853c",
   "metadata": {},
   "source": [
    "## Summary of This Notebook\n",
    "This notebook provides a hands-on guide for using the **OpenAI Responses API** to analyze tweets. \n",
    "It covers essential techniques such as:\n",
    "\n",
    "- **Creating a vector store** and uploading tweets for semantic search.\n",
    "- **Using file search** to analyze private datasets.\n",
    "- **Performing a web search** to retrieve the latest public information.\n",
    "- **Utilizing stateful responses** to maintain conversation context.\n",
    "- **Combining file and web search** to enhance retrieval-augmented generation (RAG) applications.\n",
    "\n",
    "By the end of this notebook, users will be able to integrate OpenAI's Responses API for efficient data retrieval and analysis of structured and unstructured data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbe454d-ac76-413a-b17c-f79c4873e9df",
   "metadata": {},
   "source": [
    "## Install Required Libraries\n",
    "To use the OpenAI Responses API, we need to install the following libraries:\n",
    "\n",
    "- **`openai`**: Provides access to OpenAI's APIs, including the Responses API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6346923a-a409-4621-a6fc-d0f72dccde48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9706b93-af03-4f7a-89bd-6649b11ba83c",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a4f25ea-3dc7-4955-8589-0527ce749a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import json\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818d0310-abab-49d2-9d7e-69c92112efd5",
   "metadata": {},
   "source": [
    "## Retrieve Secrets from AWS Secrets Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28c8e717-0cbb-4125-8a3e-9ea5f1c92180",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_secret(secret_name):\n",
    "    region_name = \"us-east-1\"\n",
    "\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        raise e\n",
    "\n",
    "    secret = get_secret_value_response['SecretString']\n",
    "    \n",
    "    return json.loads(secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bbd9ff-e0bc-4ec0-9fbc-b2f931defe4e",
   "metadata": {},
   "source": [
    "## Initialize OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ec97cf0-736c-439e-81e4-0d22a7b527bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "openai_api_key  = get_secret('openai')['api_key']\n",
    "\n",
    "client = OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef03684-10fa-433c-a9ff-5f322fd215c3",
   "metadata": {},
   "source": [
    "## File Search API\n",
    "\n",
    "### Introduction to File Search\n",
    "File search API enables efficient retrieval of relevant information \n",
    "from uploaded files by leveraging vector-based indexing. This feature is particularly useful \n",
    "for searching large datasets, extracting insights, and improving retrieval-augmented generation (RAG) applications.\n",
    "\n",
    "Unlike traditional keyword-based searches, the Responses API uses embeddings \n",
    "to identify semantically relevant content, making it ideal for analyzing structured \n",
    "and unstructured text data (OpenAI, 2025).\n",
    "\n",
    "For more details, visit the official OpenAI documentation: \n",
    "[File Search in Responses API](https://platform.openai.com/docs/guides/tools-file-search)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12034ce9-04cc-4f03-8573-9328f05c3735",
   "metadata": {},
   "source": [
    "### Create a Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2e24f19-be80-429e-8a9a-ece1da9a4ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vs_6917fca1950c8191936b987c0b117850\n"
     ]
    }
   ],
   "source": [
    "vector_store = client.vector_stores.create(\n",
    "    name=\"my_vector_store\"\n",
    ")\n",
    "vector_store_id = vector_store.id\n",
    "print(vector_store_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e80e5ee-4317-4317-8e46-493c3f5d2e95",
   "metadata": {},
   "source": [
    "### Upload Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "596ecef7-0b1a-4cbe-8e47-f7e13d6d6150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-1xctpDrfYUaLCjcYoLBDWD\n"
     ]
    }
   ],
   "source": [
    "with open('tweet_text.json', 'rb') as f:\n",
    "    file = client.files.create(\n",
    "        file=f,            # file-like object\n",
    "        purpose=\"assistants\"\n",
    "    )\n",
    "\n",
    "file_id = file.id\n",
    "print(file_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a4c9ed-7b16-4178-914e-a4436b6d2971",
   "metadata": {},
   "source": [
    "### Attach File to Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15874314-ed04-4315-85cc-e9ce4eee9d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-1xctpDrfYUaLCjcYoLBDWD\n"
     ]
    }
   ],
   "source": [
    "attach_status =client.vector_stores.files.create(\n",
    "    vector_store_id=vector_store_id,\n",
    "    file_id=file_id\n",
    "            )\n",
    "\n",
    "print(attach_status.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091a9cf3-a802-41a1-9707-e04ee1bdfd8f",
   "metadata": {},
   "source": [
    "### Query the Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf3753c0-b763-403d-be6a-368d80f6714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"the latest development in generativeAI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c757b4d8-d603-4b01-a610-978b9cfa5010",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = client.vector_stores.search(\n",
    "    vector_store_id=vector_store_id,\n",
    "    query=query\n",
    ")\n",
    "\n",
    "for result in search_results.data[:5]:\n",
    "    print(result.content[0].text[:100] + '\\n Relevant score: ' + str(result.score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d89abc-a919-4563-9f06-8dfc9410a4ab",
   "metadata": {},
   "source": [
    "## OpenAI Response API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee1ecaa-6836-41d5-847e-853b62bcdd0b",
   "metadata": {},
   "source": [
    "### Simple Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1c7e17d-a20d-40e2-b1bc-ee30f9199627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "As of the latest developments, generative AI continues to advance rapidly across multiple domains:\n",
       "\n",
       "1. **Text Generation**: Models like OpenAI's GPT series have become more sophisticated, with improvements in coherence, context understanding, and innovative applications such as detailed content creation, summarization, and translation.\n",
       "\n",
       "2. **Image and Video Synthesis**: Tools like DALL-E and Midjourney are producing highly detailed and creative images from text prompts, while advancements in video generation are enabling more realistic and dynamic video content.\n",
       "\n",
       "3. **Music and Audio**: AI models are capable of composing music in various styles and genres, simulating human-like voices, and even creating entirely new sounds.\n",
       "\n",
       "4. **Code Generation**: AI tools like Copilot are assisting developers by suggesting code snippets, facilitating debugging, and automating routine programming tasks.\n",
       "\n",
       "5. **Multi-modal Models**: The integration of different types of data (text, image, audio) into unified models is enhancing capabilities for more complex applications and cross-domain creative tasks.\n",
       "\n",
       "6. **Ethical AI**: There are ongoing efforts to make generative AI more ethical and transparent, with research focusing on reducing biases, improving interpretability, and ensuring responsible deployment.\n",
       "\n",
       "7. **Accessibility**: Generative AI is becoming more accessible with APIs and user-friendly interfaces, enabling a wider range of users to leverage AI capabilities in various sectors, from education to entertainment.\n",
       "\n",
       "These developments indicate a trend towards more integrated, efficient, and user-friendly AI applications with a focus on ethical considerations."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(simple_response.output_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b468693-2250-4b09-994e-2eb52b1d5741",
   "metadata": {},
   "source": [
    "### File Search Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4061d68-56f6-4dfc-974c-b2446ad79ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_search_response = client.responses.create(\n",
    "    input= query,\n",
    "    model=\"gpt-4o\",\n",
    "    temperature = 0,\n",
    "    tools=[{\n",
    "        \"type\": \"file_search\",\n",
    "        \"vector_store_ids\": [vector_store_id],\n",
    "    }]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5d448b96-b931-4af8-bd71-1f8facd44ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The latest developments in generative AI include several key advancements and applications:\n",
       "\n",
       "1. **Agentic Workflows**: Amazon Web Services is exploring the future of AI with a focus on agentic workflows, which are being showcased alongside startups like NeuralSeek and Tarpit AI.\n",
       "\n",
       "2. **AI in Supply Chain**: Atos has developed an AI-powered Supply Chain Disruption Analysis tool using generative AI, SAP BTP, and AWS Bedrock to assess risk and boost resilience.\n",
       "\n",
       "3. **Content Creation**: Generative AI is being used to create cinematic videos from prompts, incorporating audio, physics, and cameos, which is a game-changer for creators.\n",
       "\n",
       "4. **Market Growth**: The global generative AI market is expected to reach $1.18 billion this year, highlighting its rapid growth and adoption across industries.\n",
       "\n",
       "5. **Creative Industries**: Generative AI is transforming creative industries by enabling new forms of content generation and design systems.\n",
       "\n",
       "These developments illustrate the expanding role of generative AI in various sectors, from supply chain management to creative content production."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(file_search_response.output_text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddd7ddc-64d0-49dc-a0f7-c24a4a1b8c31",
   "metadata": {},
   "source": [
    "## Web Search API\n",
    "\n",
    "### Introduction to Web Search\n",
    "The OpenAI Web Search tool allows models to retrieve real-time information from the internet. \n",
    "This capability is particularly useful for obtaining up-to-date data, fact-checking, and expanding knowledge \n",
    "without relying solely on pre-trained information. \n",
    "\n",
    "By leveraging OpenAI's web search functionality, the Responses API can fetch external data \n",
    "and provide accurate, relevant results in real time (OpenAI, 2025). \n",
    "This feature enhances applications that require the latest insights, such as news aggregation, research, \n",
    "or dynamic content generation.\n",
    "\n",
    "For more details, visit the official OpenAI documentation: \n",
    "[Web Search in Responses API](https://platform.openai.com/docs/guides/tools-web-search)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f2bc7e-9a56-4695-8148-915d875ad716",
   "metadata": {},
   "source": [
    "### Perform Web Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "455aae40-d752-4e05-b8b6-da213e9b1f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_search_response = client.responses.create(\n",
    "    model=\"gpt-4o\",  # or another supported model\n",
    "    input= query,\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"web_search\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e1f5d2c4-f2fb-4261-bc7e-f5b5924f9959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here‚Äôs an in-depth update on the *latest developments in generative AI* as of today, **November 15, 2025**. I've structured the response across key areas to help you navigate the most significant breakthroughs and industry movements.  \n",
       "\n",
       "---\n",
       "\n",
       "Key Developments in Generative AI\n",
       "\n",
       "1. **OpenAI‚Äôs GPT‚Äë5.1 Release**  \n",
       "   - On **November 12, 2025**, OpenAI released **GPT‚Äë5.1**, a refined version of its GPT‚Äë5 foundation model ([en.wikipedia.org](https://en.wikipedia.org/wiki/GPT-5.1?utm_source=openai)).  \n",
       "   - GPT‚Äë5.1 introduces enhancements such as reduced hallucinations, improved instruction following, faster performance, and a more ‚Äúwarm‚Äù default personality. It includes two operational modes: **Instant**, for quick responses, and **Thinking**, optimized for complex reasoning tasks ([en.wikipedia.org](https://en.wikipedia.org/wiki/GPT-5.1?utm_source=openai)).\n",
       "\n",
       "2. **Brain‚ÄëInspired \"Dragon Hatchling\" Architecture by Pathway**  \n",
       "   - Researchers unveiled a novel architecture termed **Dragon Hatchling**, designed to mimic the dynamic neural structures of the human brain. Unlike traditional transformer-based LLMs, this model continuously adapts its internal structure in real time‚Äîforming and adjusting pathways akin to neuroplasticity.  \n",
       "   - Early tests showed performance comparable to GPT‚Äë2, signaling promise for models that can learn and generalize over time without full retraining ([livescience.com](https://www.livescience.com/technology/artificial-intelligence/new-dragon-hatchling-ai-architecture-modeled-after-the-human-brain-could-be-a-key-step-toward-agi-researchers-claim?utm_source=openai)).\n",
       "\n",
       "3. **World Generation via Spatial AI by World Labs**  \n",
       "   - **World Labs**, co-founded by Fei‚ÄëFei Li, introduced **Marble**, a generative AI tool for creating 3D worlds from text, image, or video prompts. Launched in November 2025, Marble integrates with Unity and Unreal Engine, offering creators a streamlined environment-creation workflow ([theverge.com](https://www.theverge.com/ai-artificial-intelligence/820016/world-labs-is-betting-on-world-generation-as-the-next-ai-frontier?utm_source=openai)).  \n",
       "   - The platform includes tiered pricing‚Äîstarting with a free version and scaling to a $95/month ‚ÄúMax‚Äù tier‚Äîfor commercial and advanced usage ([theverge.com](https://www.theverge.com/ai-artificial-intelligence/820016/world-labs-is-betting-on-world-generation-as-the-next-ai-frontier?utm_source=openai)).\n",
       "\n",
       "4. **DeepMind Solves Fluid Dynamics Singularity Problem**  \n",
       "   - In a breakthrough bridging generative AI and scientific research, **DeepMind** applied tailored AI models to unravel a century-old fluid dynamics problem: identifying previously unknown families of **unstable singularities**. This has wide implications for understanding turbulence, with benefits in engineering, meteorology, and medicine ([businessinsider.com](https://www.businessinsider.com/google-deepmind-cracks-century-old-physics-mystery-ai-fluid-dynamics-2025-11?utm_source=openai)).\n",
       "\n",
       "5. **Google‚Äôs Nano‚ÄØBanana‚ÄØ2 Leak ‚Äì Next-Gen Image Generator**  \n",
       "   - A leak hints at Google developing **Nano‚ÄØBanana‚ÄØ2**, a potential upgrade to its image generation tools, offering **native 2K image generation**, **4K upscaling**, and a multi-step refinement process called **‚ÄúLightbox‚Äù** to enhance realism and visual coherence ([tomsguide.com](https://www.tomsguide.com/ai/ai-image-video/nano-banana-2-leak-reveals-googles-new-studio-lightbox-heres-what-we-know?utm_source=openai)).  \n",
       "   - Though unconfirmed, this lines up with Google‚Äôs ongoing efforts to lead in AI-based creative tools ([tomsguide.com](https://www.tomsguide.com/ai/ai-image-video/nano-banana-2-leak-reveals-googles-new-studio-lightbox-heres-what-we-know?utm_source=openai)).\n",
       "\n",
       "---\n",
       "\n",
       "6. **Industry & Infrastructure Movements**\n",
       "\n",
       "   - **AWS & Anthropic Partnership**: Amazon Web Services is investing up to $4 billion in Anthropic‚Äîboth through cloud credits and equity‚Äîmaking AWS its primary cloud provider. This partnership grants Anthropic access to AWS‚Äôs Trainium and Inferentia accelerators and paves the way for Claude models on AWS Bedrock ([spglobal.com](https://www.spglobal.com/market-intelligence/en/news-insights/research/generative-ai-latest-breakthroughs-and-developments?utm_source=openai)).\n",
       "   \n",
       "   - **Oracle‚Äôs Generative AI Offering**: Oracle unveiled a beta of **OCI Generative AI**, offering Cohere-powered models (e.g., Command, Summarization, Embeddings) fully hosted on Oracle Cloud Infrastructure. This integration targets enterprise use cases in chatbots, summarization, and search, with predictable pricing and deployment security ([spglobal.com](https://www.spglobal.com/market-intelligence/en/news-insights/research/generative-ai-latest-breakthroughs-and-developments?utm_source=openai)).\n",
       "\n",
       "---\n",
       "\n",
       "Implications and Outlook\n",
       "\n",
       "- **Adaptive and Agentic Intelligence**: Models like **Dragon Hatchling** move us toward agents capable of real-time adaptation and lifelong learning‚Äîkey steps toward artificial general intelligence (AGI).  \n",
       "- **Multimodal and Spatial Creativity**: Tools such as **Marble** emphasize the expansion beyond text and image‚Äîinto immersive 3D worlds‚Äîpowering innovation in game development, architecture, media, and simulation.  \n",
       "- **Scientific & Technical Leap**: DeepMind‚Äôs singularity discovery illustrates the ability of generative AI to tackle complex scientific challenges, positioning AI as a valid co-researcher rather than just a creative tool.  \n",
       "- **Enterprise Acceleration**: Major cloud players (AWS, Oracle) are embedding generative AI into infrastructure, underscoring enterprise demand for scalable, secure, and customizable AI deployments.  \n",
       "- **Visual Fidelity Rising**: Advances like those suggested by the Nano‚ÄØBanana‚ÄØ2 leak point to a push for hyper-realistic AI-generated media that reduce manual editing needs‚Äîa potential game-changer for creative workflows.\n",
       "\n",
       "---\n",
       "\n",
       "In summary, generative AI continues to evolve rapidly‚Äîadvancing in adaptability, domain applications, scientific discovery, creative capabilities, and enterprise utility. Let me know if you‚Äôd like to deep-dive into any of these developments‚Äîfor instance, technical specifics of GPT‚Äë5.1, the architecture behind Dragon Hatchling, or Marble‚Äôs integration with game engines."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(web_search_response.output_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85df607-d638-4d58-99a8-99a6cfe2d7e8",
   "metadata": {},
   "source": [
    "### Stateful Response\n",
    "\n",
    "The OpenAI Responses API includes a stateful feature that enables continuity in interactions. \n",
    "By using the `response_id`, a conversation can persist across multiple queries, \n",
    "allowing users to refine or expand upon previous searches. This is particularly useful for iterative research, \n",
    "dynamic content generation, and applications that require follow-up queries based on prior responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b3e83a4-3437-4e9f-9732-748a35ccd43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here‚Äôs an in-depth update on the *latest developments in generative AI* as of today, **November 15, "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fetched_response = client.responses.retrieve(response_id=web_search_response.id)\n",
    "display(Markdown(fetched_response.output_text[:100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2ca4d4-b2f7-4cd2-94b6-a0d2aec179cb",
   "metadata": {},
   "source": [
    "### Continue Query with Web Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b348e31e-3aea-4656-b86e-b0f62ef9c697",
   "metadata": {},
   "outputs": [],
   "source": [
    "continue_query = 'find different news'\n",
    "\n",
    "continue_search_response = client.responses.create(\n",
    "    model=\"gpt-4o\",  # or another supported model\n",
    "    input= continue_query,\n",
    "    previous_response_id=web_search_response.id,\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"web_search\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e3ecd050-c5e3-44ca-869b-657e90aca446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is a comprehensive roundup of **recent news** and developments in **generative AI**, covering a range of innovations, concerns, and industry shifts. All information is up-to-date as of **November 15, 2025**, with each statement carefully sourced.\n",
       "\n",
       "---\n",
       "\n",
       "Nearly all global creators (86%) now employ generative AI in their workflows, with 81% acknowledging it helps them produce content they otherwise could not. Creative applications include media editing (55%), asset generation (52%), and ideation (48%). Nevertheless, a majority (69%) are concerned about their content being used without consent. This snapshot comes from a recent Adobe survey released in early November 2025. ([techradar.com](https://www.techradar.com/pro/nearly-all-creators-admit-they-use-ai-tools-for-work-so-is-this-the-end-of-true-creativity?utm_source=openai))\n",
       "\n",
       "---\n",
       "\n",
       "###  Generative AI in Business: Ambition vs. Reality\n",
       "\n",
       "A study by MIT, titled *\"The GenAI Divide: State of AI in Business 2025\"*, found that **95% of generative AI projects fail to deliver meaningful results**. Despite over **$44 billion** invested in startups and enterprise tools in the first half of 2025, most projects have not yielded notable productivity or revenue gains. The report attributes failures to inflated expectations, poor integration, and inadequate domain customization, warning of a looming ‚ÄúAI bubble.‚Äù ([timesofindia.indiatimes.com](https://timesofindia.indiatimes.com/technology/tech-news/mit-study-finds-95-of-generative-ai-projects-are-failing-only-hype-little-transformation/articleshow/123453071.cms?utm_source=openai))\n",
       "\n",
       "---\n",
       "\n",
       "###  Enterprise Solutions: Adobe AI Foundry Launch\n",
       "\n",
       "On **October 20, 2025**, Adobe unveiled **Adobe AI Foundry**, a new service that enables businesses to create customized generative AI models using their own media assets‚Äîspanning images, video, audio, and graphics. Brands like Home Depot and Disney Imagineering are early adopters. Following the announcement, Adobe‚Äôs stock rose 2.5% to **$341.55**, though it remains **down 25% year-to-date** due to stiff competition. ([investors.com](https://www.investors.com/news/technology/adobe-stock-adbe-tailored-gen-ai-models/?utm_source=openai))\n",
       "\n",
       "---\n",
       "\n",
       "###  Media & Entertainment: Netflix‚Äôs AI Integration\n",
       "\n",
       "In **July 2025**, Netflix incorporated generative AI in one of its original series‚Äî**El Eternauta**. A visually complex scene of a building collapse in Buenos Aires was created using AI-based tools, completing it **ten times faster than traditional VFX methods**. Co-CEO Ted Sarandos emphasized that AI enhances storytelling and production efficiency, rather than replacing creators. ([theguardian.com](https://www.theguardian.com/media/2025/jul/18/netflix-uses-generative-ai-in-show-for-first-time-el-eternauta?utm_source=openai))\n",
       "\n",
       "---\n",
       "\n",
       "###  Emerging Model & Tech Highlights\n",
       "\n",
       "- **Runway Gen‚Äë4 (AI Video Model)**  \n",
       "  Released in **March 2025**, this text-to-video tool generates up to 10-second clips in 720p resolution and 24 fps. It offers visual consistency within clips and incorporates features like camera movement effects and style transfer. However, consistency doesn‚Äôt extend over separate clips, and output length remains limited. ([en.wikipedia.org](https://en.wikipedia.org/wiki/Gen-4_%28AI_image_and_video_model%29?utm_source=openai))\n",
       "\n",
       "- **Kling AI (China‚Äôs Text-to-Video Model)**  \n",
       "  Developed by Kuaishou, Kling AI advanced to version **2.1 by May 2025**, offering 720p/1080p resolution, up to 30 fps, and improved realism with configurable modes. The model has also faced concerns over strict content censorship and misuse via malware from fake websites. ([en.wikipedia.org](https://en.wikipedia.org/wiki/Kling_AI?utm_source=openai))\n",
       "\n",
       "- **GPT‚Äë5.1 by OpenAI**  \n",
       "  Released on **November 12, 2025**, GPT-5.1 brings enhancements over GPT‚Äë5, including fewer hallucinations, better instruction-following, a \"warmer\" personality, and two operational modes: **Instant** (for quick answers) and **Thinking** (for deep reasoning). ([en.wikipedia.org](https://en.wikipedia.org/wiki/GPT-5.1?utm_source=openai))\n",
       "\n",
       "- **Long-Context Multimodal Models**  \n",
       "  Mid-2025 saw major AI models gain ultra-long context capabilities‚ÄîGoogle‚Äôs Gemini‚ÄØ2.5‚ÄØPro and OpenAI‚Äôs GPT‚Äë4.1 family now support up to **1 million tokens** and integrate multimodal inputs and improved reasoning. Meta also released **Llama‚ÄØ4**, a multi-modal model using a mixture-of-experts design for efficient performance. ([anvisai.com](https://anvisai.com/latest-breakthroughs-in-ai-5-key-innovations-june-2025/?utm_source=openai))\n",
       "\n",
       "- **Startups & Open-Source Advances**  \n",
       "  - **Reve Image** launched an image model noted for photorealism and superior prompt-text interpretation.  \n",
       "  - **Ideogram‚ÄØ3.0** introduced enhanced multilingual capability, style referencing, and randomness in style generation.  \n",
       "  - **Alibaba‚Äôs LHM** converts a single full-body photo into a 3D animated human avatar suitable for integration in games and virtual experiences. ([yukitaylor00.medium.com](https://yukitaylor00.medium.com/ai-weekly-top-10-ai-breakthroughs-you-missed-this-week-march-2025-1d742259e5b8?utm_source=openai))\n",
       "\n",
       "- **Hardware & Regulation Trends**  \n",
       "  AI regulation advanced significantly in 2025. The **EU AI Act** has gone into effect, establishing safety and transparency rules. The **US** launched a National AI Safety Board, while **China** imposed tighter audits on generative models. Meanwhile, hardware innovation accelerated with NVIDIA‚Äôs **Blackwell architecture** offering ~40% performance improvements, and Apple's **Neural Engine 2.0** enabling efficient on-device AI. ([bytenest.tech](https://bytenest.tech/latest-news-on-artificial-intelligence-in-2025-key-trends-breakthroughs-and-challenges/?utm_source=openai))\n",
       "\n",
       "---\n",
       "\n",
       "###  Summary Table\n",
       "\n",
       "| Area                 | Key Highlights                                                                 |\n",
       "|----------------------|--------------------------------------------------------------------------------|\n",
       "| Creator Sentiment     | 86% use generative AI; 81% see creative gains; concerns over training usage     |\n",
       "| Enterprise Reality   | 95% of projects fail; Adobe moves to bespoke models for brands                 |\n",
       "| Media & VFX          | Netflix achieves 10√ó faster VFX via generative AI                              |\n",
       "| Model Innovation     | GPT‚Äë5.1, Runway Gen‚Äë4, Kling AI, long-context multimodal models, open-source     |\n",
       "| Regulations & Hardware | EU AI Act effective; US safety board; hardware boosts from NVIDIA and Apple   |\n",
       "\n",
       "---\n",
       "\n",
       "In summary, while generative AI continues to **expand creatively and technologically**‚Äîfrom personalized enterprise tools to groundbreaking model capabilities‚Äîit also faces challenges like project failure, ethical concerns, and regulatory hurdles. If you'd like, I can explore any of these developments further‚Äîjust let me know which interests you most!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(continue_search_response.output_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132125be-48d9-4596-9dc5-bc12dca5fdbf",
   "metadata": {},
   "source": [
    "### Combining File Search and Web Search\n",
    "\n",
    "This is an example of using file search to analyze private data and web search to retrieve public or the latest data. \n",
    "The Responses API allows developers to integrate these tools to enhance retrieval-augmented generation (RAG) applications. \n",
    "By combining file search with web search, users can leverage structured internal knowledge while also retrieving real-time \n",
    "information from external sources, ensuring comprehensive and up-to-date responses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6344e43c-8aa4-4693-aaf6-20f09f416364",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_search_response = client.responses.create(\n",
    "    model=\"gpt-4o\",  # or another supported model\n",
    "    input= query,\n",
    "    temperature = 0,\n",
    "    instructions=\"Retrieve the results from the file search first, and use the web search tool to expand the results with news resources\",\n",
    "    tools=[{\n",
    "        \"type\": \"file_search\",\n",
    "        \"vector_store_ids\": [vector_store_id],\n",
    "    },\n",
    "        {\n",
    "            \"type\": \"web_search\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a09ee0a6-3b50-43a3-a63b-3c765da85561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here‚Äôs a comprehensive and up-to-date overview of the **latest developments in generative AI** as of **November 15, 2025**, with detailed citations and structured analysis:\n",
       "\n",
       "---\n",
       "\n",
       "##  Major Model Releases and Innovations\n",
       "\n",
       "- **OpenAI GPT‚Äë5.1**  \n",
       "  Released on **November 12, 2025**, GPT‚Äë5.1 is the newest iteration in OpenAI‚Äôs GPT series. It introduces eight selectable personality options, improved instruction-following, reduced hallucinations, and two operational modes: **Instant** (for speed) and **Thinking** (for complex reasoning tasks) ([en.wikipedia.org](https://en.wikipedia.org/wiki/GPT-5.1?utm_source=openai)).\n",
       "\n",
       "- **OpenAI GPT‚Äë5**  \n",
       "  Launched earlier on **August 7, 2025**, GPT‚Äë5 unified reasoning and multimodal capabilities under a single interface and was integrated into ChatGPT and Microsoft Copilot ([en.wikipedia.org](https://en.wikipedia.org/wiki/GPT-5?utm_source=openai)).\n",
       "\n",
       "- **OpenAI o4‚Äëmini**  \n",
       "  Released on **April 16, 2025**, this compact reasoning model supports both text and image inputs, including whiteboard sketch analysis. A higher-accuracy variant, **o4‚Äëmini‚Äëhigh**, is available to paid-tier users ([en.wikipedia.org](https://en.wikipedia.org/wiki/OpenAI_o4-mini?utm_source=openai)).\n",
       "\n",
       "- **Google Gemini 2.5 Pro & Flash**  \n",
       "  Google‚Äôs Gemini 2.5 Pro (with ‚ÄúDeep Think‚Äù reasoning mode) and Flash models became generally available on **June 17, 2025**. These models offer enhanced reasoning, coding capabilities, native audio output, and a massive 1 million token context window ([en.wikipedia.org](https://en.wikipedia.org/wiki/Gemini_%28language_model%29?utm_source=openai)).\n",
       "\n",
       "- **Nano Banana (Gemini 2.5 Flash Image)**  \n",
       "  Launched on **August 26, 2025**, this image generation and editing model went viral for its photorealistic ‚Äú3D figurine‚Äù outputs. It supports features like subject consistency, multi-image fusion, and SynthID watermarking. Within weeks, it attracted over 10 million new users and facilitated more than 200 million image edits ([en.wikipedia.org](https://en.wikipedia.org/wiki/Nano_Banana?utm_source=openai)).\n",
       "\n",
       "- **Other Notable Models**  \n",
       "  - **GPT‚Äë4.5 (Orion)**: Released in **February 2025**, it offers reduced hallucinations, improved accuracy, and a large context window, excelling in creative and emotionally intelligent tasks ([medium.com](https://medium.com/%4017shubhanshujain/top-generative-ai-trends-for-2025-gpt-4-5-gemini-2-5-and-ethical-implications-94a126df84d8?utm_source=openai)).  \n",
       "  - **Llama 4 Family**: Released by Meta on **April 5, 2025**, these open-source models support early-fusion multimodality, MoE architecture, and extensive language coverage ([medium.com](https://medium.com/%4017shubhanshujain/top-generative-ai-trends-for-2025-gpt-4-5-gemini-2-5-and-ethical-implications-94a126df84d8?utm_source=openai)).  \n",
       "  - **Baidu Ernie 4.5 & Ernie X1**: Announced in **April 2025**, these multimodal and reasoning models reportedly outperform competitors on benchmarks. Ernie 4.5 is slated to become open-source from **June 30, 2025** ([globenewswire.com](https://www.globenewswire.com/news-release/2025/04/17/3063915/0/en/Applied-Generative-AI-Course-Launched-by-Interview-Kickstart-2025-Best-GenAI-Course-With-Agentic-AI-Projects-For-Top-AI-Jobs-at-Google-Meta-Netflix-Microsoft-OpenAI-Nvidia.html?utm_source=openai)).\n",
       "\n",
       "---\n",
       "\n",
       "##  Emerging Trends and Market Dynamics\n",
       "\n",
       "- **Agentic AI and Autonomous Agents**  \n",
       "  The shift from AI as copilots to fully autonomous agents is accelerating. Agentic AI systems can plan, act, and adapt independently‚Äîexpected to be a dominant trend in 2026 and beyond ([simplilearn.com](https://www.simplilearn.com/top-technology-trends-and-jobs-article?utm_source=openai)).\n",
       "\n",
       "- **Generative AI Market Growth**  \n",
       "  The generative AI market experienced triple-digit growth across hardware, foundation models, and development platforms in 2024. Forecasts estimate over **US$400 billion** in AI-related spending in 2025 ([businesswire.com](https://www.businesswire.com/news/home/20250825682581/en/Generative-AI-Market-Report-2025-GenAI-Market-Experienced-Triple-digit-growth-Rates-in-All-Three-Major-Segments-Spanning-GenAI-Hardware-Foundation-Models-and-Development-Platforms---ResearchAndMarkets.com?utm_source=openai)).\n",
       "\n",
       "- **Enterprise Adoption and Scaling**  \n",
       "  According to McKinsey‚Äôs 2025 Global AI Survey, about one-third of organizations are scaling AI programs, while 23% are deploying agentic AI systems. High performers are investing heavily‚Äîover 20% of digital budgets‚Äîinto AI and redesigning workflows to capture value ([mckinsey.com](https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai?utm_source=openai)).\n",
       "\n",
       "- **Responsible AI Practices**  \n",
       "  UC Berkeley released a ‚ÄúResponsible Use of Generative AI‚Äù playbook outlining ten actionable strategies for business leaders and product managers to ensure ethical and responsible deployment of GenAI ([weforum.org](https://www.weforum.org/stories/2025/06/responsible-generative-ai-product-development-use/?utm_source=openai)).\n",
       "\n",
       "- **Generative AI in Software Development**  \n",
       "  Bain‚Äôs September 2025 report highlights that while GenAI tools boost productivity, organizations must adapt processes to realize real value from these technologies ([bain.com](https://www.bain.com/insights/from-pilots-to-payoff-generative-ai-in-software-development-technology-report-2025/?utm_source=openai)).\n",
       "\n",
       "- **Hardware Innovations**  \n",
       "  Qualcomm unveiled the **AI200** and **AI250** inference accelerators, targeting data center deployment in 2026 and 2027. These systems emphasize scalability, efficiency, and compatibility with major AI frameworks ([tomshardware.com](https://www.tomshardware.com/tech-industry/artificial-intelligence/qualcomm-unveils-ai200-and-ai250-ai-inference-accelerators-hexagon-takes-on-amd-and-nvidia-in-the-booming-data-center-realm?utm_source=openai)).\n",
       "\n",
       "---\n",
       "\n",
       "##  Consumer-Facing and Multimedia Advances\n",
       "\n",
       "- **OpenAI Sora 2 and Sora App**  \n",
       "  On **September 30, 2025**, OpenAI launched **Sora 2**, a multimodal video+audio generation model, alongside the **Sora app**‚Äîa social-style platform for short AI-generated clips. The launch raised significant discussions around IP, moderation, and deepfake risks ([champaignmagazine.com](https://champaignmagazine.com/2025/10/05/ai-by-ai-weekly-top-5-september-29-october-5-2025/?utm_source=openai)).\n",
       "\n",
       "- **Google Veo 3.1**  \n",
       "  Released in **October 2025**, Veo 3.1 enhances narrative control in generative video, enabling seamless transitions, character consistency, and integrated audio. It‚Äôs available via Gemini API and Google‚Äôs Flow editing tool ([voxfor.com](https://www.voxfor.com/what-is-new-in-ai-the-latest-news-from-october-2025/?utm_source=openai)).\n",
       "\n",
       "- **Anthropic Claude Haiku 4.5**  \n",
       "  Also launched in **October 2025**, this compact model delivers flagship-level reasoning and coding performance at significantly higher speed and lower cost. It supports agentic capabilities like ‚Äúusing computers‚Äù and process identification ([voxfor.com](https://www.voxfor.com/what-is-new-in-ai-the-latest-news-from-october-2025/?utm_source=openai)).\n",
       "\n",
       "---\n",
       "\n",
       "##  Academic and Research Developments\n",
       "\n",
       "- **Chronologically Consistent Generative AI**  \n",
       "  A recent October 2025 study introduced models trained only on data available before a defined cutoff, eliminating lookahead bias. These models offer replicability and conservative forecast accuracy, useful for prediction tasks ([arxiv.org](https://arxiv.org/abs/2510.11677?utm_source=openai)).\n",
       "\n",
       "- **Agentic AI Networking in 6G**  \n",
       "  A March 2025 research paper proposed **AgentNet**, a framework for collaborative, embodied AI agents in networking environments. It envisions generative foundation models acting as agents in industrial automation and metaverse infotainment systems ([arxiv.org](https://arxiv.org/abs/2503.15764?utm_source=openai)).\n",
       "\n",
       "---\n",
       "\n",
       "##  Summary Table\n",
       "\n",
       "| Category                  | Key Developments                                                                 |\n",
       "|---------------------------|----------------------------------------------------------------------------------|\n",
       "| Model Releases            | GPT‚Äë5.1, GPT‚Äë5, o4‚Äëmini, Gemini 2.5 Pro/Flash, Nano Banana, GPT‚Äë4.5, Llama 4, Ernie 4.5/X1 |\n",
       "| Market & Enterprise Trends| Agentic AI, market growth, enterprise scaling, responsible AI, hardware advances |\n",
       "| Consumer & Multimedia     | Sora 2, Veo 3.1, Claude Haiku 4.5                                               |\n",
       "| Research & Academia       | Chronologically consistent models, AgentNet for 6G networks                      |\n",
       "\n",
       "---\n",
       "\n",
       "###  Final Thoughts\n",
       "\n",
       "The generative AI landscape in late 2025 is defined by rapid innovation across models, enterprise adoption, hardware, and ethical frameworks. Notably:\n",
       "\n",
       "- **GPT‚Äë5.1** (Nov 12) and **Nano Banana** (Aug 26) are among the most recent high-impact releases.\n",
       "- **Agentic AI** is emerging as a transformative trend, with enterprises beginning to scale such systems.\n",
       "- **Responsible AI** and **hardware infrastructure** are becoming critical enablers of sustainable and scalable AI deployment.\n",
       "- **Consumer-facing tools** like Sora 2 and Veo 3.1 are pushing generative AI into mainstream creative workflows.\n",
       "\n",
       "Let me know if you'd like a deeper dive into any specific model, trend, or application area!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(combined_search_response.output_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cac39c8-d345-4faf-a98f-2301b96e80a2",
   "metadata": {},
   "source": [
    "# üß© Try It Yourself: Two-Step RAG (Private Data + Combined Search)\n",
    "\n",
    "## Step 1 ‚Äî Upload & Create Vector Store\n",
    "1. Upload a short text file (e.g., `my_notes.txt`) to your notebook instance.  \n",
    "2. Create a **vector store** and **ingest** your uploaded file.  \n",
    "3. Run a simple test query to verify retrieval:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a821302-9a2f-4d19-ba68-3822e46f9a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vs_6917fca1950c8191936b987c0b117850\n"
     ]
    }
   ],
   "source": [
    "vector_store = client.vector_stores.create(\n",
    "    name=\"my_vector_store\"\n",
    ")\n",
    "vector_store_id = vector_store.id\n",
    "print(vector_store_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "07491dd3-2606-4c65-802f-a8f1b06cac7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-6bcYuAv1fiyC1mW6oj9qFN\n"
     ]
    }
   ],
   "source": [
    "with open('sports_notes.txt', 'rb') as f:\n",
    "    file = client.files.create(\n",
    "        file=f,            # file-like object\n",
    "        purpose=\"assistants\"\n",
    "    )\n",
    "\n",
    "file_id = file.id\n",
    "print(file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "07cb04be-a24b-486b-88aa-6f30a1ab88f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-6bcYuAv1fiyC1mW6oj9qFN\n"
     ]
    }
   ],
   "source": [
    "attach_status =client.vector_stores.files.create(\n",
    "    vector_store_id=vector_store_id,\n",
    "    file_id=file_id\n",
    "            )\n",
    "\n",
    "print(attach_status.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "093b56bb-828b-475c-b1a1-886b35ffbe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Explain the rules of basketball\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "37648180-12be-4cc9-be54-daa15de37789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basketball relies heavily on teamwork, spacing, and fast transitions from defense to offense.\n",
      "Soccer\n",
      " Relevant score: 0.15570516833258916\n",
      "They have been VERY clear that Chatgpt, these AI videos‚Ä¶\"\n",
      "  }\n",
      "},\n",
      "{\n",
      "  \"_id\": {\n",
      "    \"$oid\": \"68e56b1e1\n",
      " Relevant score: 0.006318813056261807\n",
      "They have been VERY clear that Chatgpt, these AI videos‚Ä¶\"\n",
      "  }\n",
      "},\n",
      "{\n",
      "  \"_id\": {\n",
      "    \"$oid\": \"68e56b1f1\n",
      " Relevant score: 0.004876320483920653\n",
      "They have been VERY clear that Chatgpt, these AI videos‚Ä¶\"\n",
      "  }\n",
      "},\n",
      "{\n",
      "  \"_id\": {\n",
      "    \"$oid\": \"68e56b1d1\n",
      " Relevant score: 0.003997826679217775\n",
      "They have been VERY clear that Chatgpt, these AI videos‚Ä¶\"\n",
      "  }\n",
      "},\n",
      "{\n",
      "  \"_id\": {\n",
      "    \"$oid\": \"68e56b1f1\n",
      " Relevant score: 0.0035837128264293674\n"
     ]
    }
   ],
   "source": [
    "search_results = client.vector_stores.search(\n",
    "    vector_store_id=vector_store_id,\n",
    "    query=query\n",
    ")\n",
    "\n",
    "for result in search_results.data[:5]:\n",
    "    print(result.content[0].text[:100] + '\\n Relevant score: ' + str(result.score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c43361-5d0a-4aaf-9476-edada3f1e521",
   "metadata": {},
   "source": [
    "## Step 2 ‚Äî Combine File Search with Web Search\n",
    "1. Enable both **file_search** and **web_search** in the Responses API.  \n",
    "2. Use a prompt that asks the model to merge insights from both sources.  \n",
    "   > Example: ‚ÄúUsing my uploaded notes and the latest web information, summarize the current trends on this topic.‚Äù  \n",
    "3. Review how the answer from your file and **current info** from the web.\n",
    "\n",
    "‚úÖ You‚Äôve created a RAG system that combines **private** and **public** data for comprehensive, up-to-date analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b1b9195a-b8b0-453e-b1fd-933fc5f154fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_search_response = client.responses.create(\n",
    "    input= query,\n",
    "    model=\"gpt-4o\",\n",
    "    temperature = 0,\n",
    "    tools=[{\n",
    "        \"type\": \"file_search\",\n",
    "        \"vector_store_ids\": [vector_store_id],\n",
    "    }]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9ebdf46f-f308-486d-b45a-a405906430cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Basketball is a team sport with specific rules that govern gameplay. Here are the basic rules:\n",
       "\n",
       "1. **Objective**: The main goal is to score points by shooting the basketball through the opponent's hoop.\n",
       "\n",
       "2. **Teams**: Each team consists of five players on the court at a time.\n",
       "\n",
       "3. **Game Duration**: A standard game is divided into four quarters, each lasting 12 minutes in the NBA. Other leagues may have different durations.\n",
       "\n",
       "4. **Scoring**: Points are scored as follows:\n",
       "   - Field goals are worth two points, or three points if the shooter is behind the three-point line.\n",
       "   - Free throws are worth one point each.\n",
       "\n",
       "5. **Dribbling**: Players must dribble the ball (bounce it on the floor) while moving. If a player stops dribbling, they cannot start again until another player touches the ball.\n",
       "\n",
       "6. **Violations**: Common violations include traveling (taking too many steps without dribbling), double dribble (dribbling with both hands or starting to dribble again after stopping), and shot clock violations (failing to attempt a shot within the allotted time).\n",
       "\n",
       "7. **Fouls**: Physical contact that impedes an opponent can result in a foul. Accumulating too many fouls can lead to free throws for the opposing team.\n",
       "\n",
       "8. **Possession**: The game starts with a jump ball, and possession alternates between teams after each quarter.\n",
       "\n",
       "9. **Defense**: Teams can play man-to-man or zone defense to prevent the opposing team from scoring.\n",
       "\n",
       "10. **Substitutions**: Players can be substituted in and out of the game during stoppages in play.\n",
       "\n",
       "These rules ensure fair play and structure within the game, allowing for competitive and strategic gameplay."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(file_search_response.output_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c054e1f3-7e52-44c6-a546-c61b145839d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_search_response = client.responses.create(\n",
    "    model=\"gpt-4o\",  # or another supported model\n",
    "    input= query,\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"web_search\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d8a48992-b4dc-4adb-b724-78a003142d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Basketball is a team sport with specific rules that govern gameplay. Here are the basic rules:\n",
       "\n",
       "1. **Objective**: The main goal is to score points by shooting the basketball through the opponent's hoop.\n",
       "\n",
       "2. **Teams**: Each team consists of five players on the court at a time.\n",
       "\n",
       "3. **Game Duration**: A standard game is divided into four quarters, each lasting 12 minutes in the NBA. Other leagues may have different durations.\n",
       "\n",
       "4. **Scoring**: Points are scored as follows:\n",
       "   - Field goals are worth two points, or three points if the shooter is behind the three-point line.\n",
       "   - Free throws are worth one point each.\n",
       "\n",
       "5. **Dribbling**: Players must dribble the ball (bounce it on the floor) while moving. If a player stops dribbling, they cannot start again until another player touches the ball.\n",
       "\n",
       "6. **Violations**: Common violations include traveling (taking too many steps without dribbling), double dribble (dribbling with both hands or starting to dribble again after stopping), and shot clock violations (failing to attempt a shot within the allotted time).\n",
       "\n",
       "7. **Fouls**: Physical contact that impedes an opponent can result in a foul. Accumulating too many fouls can lead to free throws for the opposing team.\n",
       "\n",
       "8. **Possession**: The game starts with a jump ball, and possession alternates between teams after each quarter.\n",
       "\n",
       "9. **Defense**: Teams can play man-to-man or zone defense to prevent the opposing team from scoring.\n",
       "\n",
       "10. **Substitutions**: Players can be substituted in and out of the game during stoppages in play.\n",
       "\n",
       "These rules ensure fair play and structure within the game, allowing for competitive and strategic gameplay."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(file_search_response.output_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4c2e1b21-02e9-4bc4-bb58-32838b537272",
   "metadata": {},
   "outputs": [],
   "source": [
    "continue_query = '‚ÄúSummarize the different types of t.‚Äù'\n",
    "\n",
    "continue_search_response = client.responses.create(\n",
    "    model=\"gpt-4o\",  # or another supported model\n",
    "    input= continue_query,\n",
    "    previous_response_id=web_search_response.id,\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"web_search\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c1833fb5-9bfe-4de5-b25a-00fe443cc9f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "It seems you mentioned uploading notes, but I don't have access to external files. If you provide key points or text from your notes, I can help incorporate them with the latest information from the web. Let me know how you'd like to proceed!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(continue_search_response.output_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad6046d-d895-4001-8e61-1dac429a0c75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
